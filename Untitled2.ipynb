{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d563f905-08d9-4e45-bba9-7fd088593d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51a6bf4-3e46-4815-860d-adfad2d226bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Test_Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381b3000-93d1-481a-805e-c60d034859f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.40:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test_Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a48e2c4d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9e42095-7313-4b8f-b1ad-1ee36325a1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df = spark.range(10)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9e50c51-0bb4-402c-b6c5-90fa8aa26da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|id2|\n",
      "+---+---+\n",
      "|  2|  2|\n",
      "|  4|  4|\n",
      "|  6|  6|\n",
      "|  8|  8|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.range(2,20,2)\n",
    "df.join(df2, df.id == df2.id, 'inner').select(df.id,df2.id.alias('id2')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9136c0d0-640d-4a25-aa6c-cd836cdb32fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').load(r'C:\\Users\\Rahul\\Desktop\\Project\\Final_Train.csv',header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa66672e-ec11-44e8-8a73-4fcde274ab25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BHMS', ' MD - Homeopathy']\n",
      "['24 years experience']\n",
      "['100%']\n",
      "['Kakkanad', ' Ernakulam']\n",
      "['Homeopath']\n",
      "['100% 16 Feedback Kakkanad', ' Ernakulam']\n",
      "['100']\n"
     ]
    }
   ],
   "source": [
    "for i in list(df.take(2)[0]):\n",
    "    print (i.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0fdf8433-4913-48c4-a1e7-76cb4188769b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------+--------------------+----+------+\n",
      "|       Qualification|         Experience|Rating|               Place| Profile|  Miscellaneous_Info|Fees|Ranked|\n",
      "+--------------------+-------------------+------+--------------------+--------+--------------------+----+------+\n",
      "| BAMS, MS - Ayurveda|10 years experience|  null|   Bakkarwala, Delhi|Ayurveda|                null| 150|     1|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|Ayurveda|98% 76 Feedback W...| 350|     1|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|Ayurveda|Bannerghatta Road...| 250|     2|\n",
      "|                BAMS|12 years experience|   96%|  Dadar West, Mumbai|Ayurveda|96% 30 Feedback D...| 100|     3|\n",
      "|BAMS, MD - Acupun...|15 years experience|  null|Anna Nagar East, ...|Ayurveda|                null| 250|     1|\n",
      "| BAMS, MS - Ayurveda|16 years experience|  100%|Yelahanka, Bangalore|Ayurveda|100% 3 Feedback Y...| 300|     1|\n",
      "|MD - Ayurveda Med...|20 years experience|  null|Goregaon West, Mu...|Ayurveda|                null| 500|     1|\n",
      "|                BAMS|20 years experience|  null|     Sagarpur, Delhi|Ayurveda|                null|  50|     2|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|Ayurveda|100% 4 Feedback K...| 250|     3|\n",
      "|                BAMS|27 years experience|  null|Dahisar East, Mumbai|Ayurveda|                null| 100|     1|\n",
      "|BAMS, Diploma in ...|31 years experience|  100%| RT Nagar, Bangalore|Ayurveda|100% 7 Feedback R...| 500|     1|\n",
      "|                BAMS| 7 years experience|  null|Somajiguda, Hyder...|Ayurveda|                null| 100|     1|\n",
      "|BAMS, Post Gradua...| 8 years experience|  null|Dahisar West, Mumbai|Ayurveda|                null|  50|     1|\n",
      "|                BAMS| 8 years experience|  null|Saroor Nagar, Hyd...|Ayurveda|                null| 300|     2|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|Ayurveda|                null| 100|     3|\n",
      "|                BAMS| 9 years experience|  null| IP Extension, Delhi|Ayurveda|                null| 300|     1|\n",
      "|                BAMS| 9 years experience|  100%|     KPHB, Hyderabad|Ayurveda|Arthritis Managem...| 300|     1|\n",
      "|                BAMS| 9 years experience|  null|    Chetpet, Chennai|Ayurveda|                null| 150|     3|\n",
      "|                 BDS|10 years experience|  null|New Friends Colon...| Dentist|Dental Fillings R...| 250|     1|\n",
      "|                 BDS|10 years experience|  null|Hazrat Nizamuddin...| Dentist|Hazrat Nizamuddin...| 250|     1|\n",
      "+--------------------+-------------------+------+--------------------+--------+--------------------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Ranked\",rank().over(Window.partitionBy(df.Profile,df.Experience).orderBy(desc(df.Fees)))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd670a36-3f2b-4c63-800c-682257e6d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64c0b04d-9214-49d9-b49e-d3f569ba39d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+------+\n",
      "|       Qualification|         Experience|Rating|               Place|         Profile|  Miscellaneous_Info|Fees|   New|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+------+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|       Homeopath|100% 16 Feedback ...| 100|1100.0|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|        Ayurveda|98% 76 Feedback W...| 350| 850.0|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|  ENT Specialist|                null| 300| 900.0|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|        Ayurveda|Bannerghatta Road...| 250| 950.0|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|        Ayurveda|100% 4 Feedback K...| 250| 950.0|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|        Ayurveda|                null| 100|1100.0|\n",
      "|                BHMS|42 years experience|  null|   Karol Bagh, Delhi|       Homeopath|                null| 200|1000.0|\n",
      "|                 BDS|10 years experience|   99%|  Arekere, Bangalore|         Dentist|Dental Fillings C...| 200|1000.0|\n",
      "|MBBS, MD - Genera...|14 years experience|  null| Old City, Hyderabad|General Medicine|                null| 100|1100.0|\n",
      "|            BSc, BDS|23 years experience|  null|   Athani, Ernakulam|         Dentist|                null| 100|1100.0|\n",
      "| MBBS, MS, DNB - ENT| 5 years experience|  null|Thousand Lights, ...|  ENT Specialist|                null| 700| 500.0|\n",
      "|                BAMS| 7 years experience|  null|Somajiguda, Hyder...|        Ayurveda|                null| 100|1100.0|\n",
      "|            BDS, MDS| 9 years experience|   98%|Coimbatore Raceco...|         Dentist|98% 14 Feedback C...| 200|1000.0|\n",
      "|BDS, MDS - Oral &...|21 years experience|  null|Jubilee Hills, Hy...|         Dentist|Dental Crowns Fac...| 350| 850.0|\n",
      "|MBBS, Diploma in ...|12 years experience|  null|       Kondli, Delhi|  ENT Specialist|                null| 500| 700.0|\n",
      "|MBBS, MD - Genera...|10 years experience|  null|Saroor Nagar, Hyd...|General Medicine|                null| 200|1000.0|\n",
      "|MBBS, Diploma in ...|24 years experience|  null|Tambaram West, Ch...|  ENT Specialist|                null| 100|1100.0|\n",
      "|MBBS, MF- Homeopathy| 5 years experience|  null|Purasawakkam, Che...|       Homeopath|                null| 300| 900.0|\n",
      "|      MBBS, MS - ENT|19 years experience|   79%|     KPHB, Hyderabad|  ENT Specialist|79% 8 Feedback KP...| 400| 800.0|\n",
      "|                MBBS|19 years experience|  100%|HSR Layout, Banga...|General Medicine|100% 4 Feedback H...| 150|1050.0|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('New',1200-df.Fees).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bfbf845-22b5-40dd-b338-fc97da638c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *#col, expr, split, regexp_replace, count,sum,col,desc,rank\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "df.createOrReplaceTempView('df_Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02ad3ed1-6353-4842-a641-d6ce55b395d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50c4d973-d709-4798-a866-18036306f5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "| Profile|         Experience|Fees|RANK() OVER (PARTITION BY Profile, Experience ORDER BY Fees DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)|\n",
      "+--------+-------------------+----+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|Ayurveda|10 years experience| 150|                                                                                                                            1|\n",
      "|Ayurveda|12 years experience| 350|                                                                                                                            1|\n",
      "|Ayurveda|12 years experience| 250|                                                                                                                            2|\n",
      "|Ayurveda|12 years experience| 100|                                                                                                                            3|\n",
      "|Ayurveda|15 years experience| 250|                                                                                                                            1|\n",
      "|Ayurveda|16 years experience| 300|                                                                                                                            1|\n",
      "|Ayurveda|20 years experience| 500|                                                                                                                            1|\n",
      "|Ayurveda|20 years experience|  50|                                                                                                                            2|\n",
      "|Ayurveda|20 years experience| 250|                                                                                                                            3|\n",
      "|Ayurveda|27 years experience| 100|                                                                                                                            1|\n",
      "|Ayurveda|31 years experience| 500|                                                                                                                            1|\n",
      "|Ayurveda| 7 years experience| 100|                                                                                                                            1|\n",
      "|Ayurveda| 8 years experience|  50|                                                                                                                            1|\n",
      "|Ayurveda| 8 years experience| 300|                                                                                                                            2|\n",
      "|Ayurveda| 8 years experience| 100|                                                                                                                            3|\n",
      "|Ayurveda| 9 years experience| 300|                                                                                                                            1|\n",
      "|Ayurveda| 9 years experience| 300|                                                                                                                            1|\n",
      "|Ayurveda| 9 years experience| 150|                                                                                                                            3|\n",
      "| Dentist|10 years experience| 250|                                                                                                                            1|\n",
      "| Dentist|10 years experience| 250|                                                                                                                            1|\n",
      "+--------+-------------------+----+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Profile,df.Experience,df.Fees,rank().over(Window.partitionBy(df.Profile,df.Experience).orderBy(desc(df.Fees)))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b922577-7c15-4672-a8bd-c260fda73265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+-----+\n",
      "|       Qualification|         Experience|Rating|               Place|         Profile|  Miscellaneous_Info|Fees| new2|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+-----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|       Homeopath|100% 16 Feedback ...| 100| true|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|        Ayurveda|98% 76 Feedback W...| 350| true|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|  ENT Specialist|                null| 300| true|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|        Ayurveda|Bannerghatta Road...| 250| true|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|        Ayurveda|100% 4 Feedback K...| 250| true|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|        Ayurveda|                null| 100| true|\n",
      "|                BHMS|42 years experience|  null|   Karol Bagh, Delhi|       Homeopath|                null| 200| true|\n",
      "|                 BDS|10 years experience|   99%|  Arekere, Bangalore|         Dentist|Dental Fillings C...| 200| true|\n",
      "|MBBS, MD - Genera...|14 years experience|  null| Old City, Hyderabad|General Medicine|                null| 100| true|\n",
      "|            BSc, BDS|23 years experience|  null|   Athani, Ernakulam|         Dentist|                null| 100| true|\n",
      "| MBBS, MS, DNB - ENT| 5 years experience|  null|Thousand Lights, ...|  ENT Specialist|                null| 700|false|\n",
      "|                BAMS| 7 years experience|  null|Somajiguda, Hyder...|        Ayurveda|                null| 100| true|\n",
      "|            BDS, MDS| 9 years experience|   98%|Coimbatore Raceco...|         Dentist|98% 14 Feedback C...| 200| true|\n",
      "|BDS, MDS - Oral &...|21 years experience|  null|Jubilee Hills, Hy...|         Dentist|Dental Crowns Fac...| 350| true|\n",
      "|MBBS, Diploma in ...|12 years experience|  null|       Kondli, Delhi|  ENT Specialist|                null| 500|false|\n",
      "|MBBS, MD - Genera...|10 years experience|  null|Saroor Nagar, Hyd...|General Medicine|                null| 200| true|\n",
      "|MBBS, Diploma in ...|24 years experience|  null|Tambaram West, Ch...|  ENT Specialist|                null| 100| true|\n",
      "|MBBS, MF- Homeopathy| 5 years experience|  null|Purasawakkam, Che...|       Homeopath|                null| 300| true|\n",
      "|      MBBS, MS - ENT|19 years experience|   79%|     KPHB, Hyderabad|  ENT Specialist|79% 8 Feedback KP...| 400|false|\n",
      "|                MBBS|19 years experience|  100%|HSR Layout, Banga...|General Medicine|100% 4 Feedback H...| 150| true|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('new2',col('Fees') <= 350).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84213a1-e206-4bd7-b2d0-c71a7b153759",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------+---------+---------+\n",
      "| Profile|               Place|sum(Fees)|max(Fees)|min(Fees)|\n",
      "+--------+--------------------+---------+---------+---------+\n",
      "|Ayurveda|Anna Nagar East, ...|    250.0|      250|      250|\n",
      "|Ayurveda|   Bakkarwala, Delhi|    150.0|      150|      150|\n",
      "|Ayurveda|Bannerghatta Road...|    250.0|      250|      250|\n",
      "|Ayurveda|    Chetpet, Chennai|    150.0|      150|      150|\n",
      "|Ayurveda|  Dadar West, Mumbai|    100.0|      100|      100|\n",
      "|Ayurveda|Dahisar East, Mumbai|    100.0|      100|      100|\n",
      "|Ayurveda|Dahisar West, Mumbai|     50.0|       50|       50|\n",
      "|Ayurveda|Goregaon West, Mu...|    500.0|      500|      500|\n",
      "|Ayurveda| IP Extension, Delhi|    300.0|      300|      300|\n",
      "|Ayurveda|     KPHB, Hyderabad|    300.0|      300|      300|\n",
      "|Ayurveda|Keelkattalai, Che...|    250.0|      250|      250|\n",
      "|Ayurveda|      Porur, Chennai|    100.0|      100|      100|\n",
      "|Ayurveda| RT Nagar, Bangalore|    500.0|      500|      500|\n",
      "|Ayurveda|     Sagarpur, Delhi|     50.0|       50|       50|\n",
      "|Ayurveda|Saroor Nagar, Hyd...|    300.0|      300|      300|\n",
      "|Ayurveda|Somajiguda, Hyder...|    100.0|      100|      100|\n",
      "|Ayurveda|Whitefield, Banga...|    350.0|      350|      350|\n",
      "|Ayurveda|Yelahanka, Bangalore|    300.0|      300|      300|\n",
      "| Dentist|AS Rao Nagar, Hyd...|    200.0|      200|      200|\n",
      "| Dentist|   Ambattur, Chennai|    100.0|      100|      100|\n",
      "+--------+--------------------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Profile','Place').agg(sum('Fees'), max('Fees'), min('Fees')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0324ce-1a3b-46e1-86a6-e4d8e98d6ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------+\n",
      "|       Qualification|split(Qualification, -, -1)[0]|\n",
      "+--------------------+------------------------------+\n",
      "|BHMS, MD - Homeop...|                     BHMS, MD |\n",
      "|BAMS, MD - Ayurve...|                     BAMS, MD |\n",
      "|MBBS, MS - Otorhi...|                     MBBS, MS |\n",
      "| BSc - Zoology, BAMS|                          BSc |\n",
      "|                BAMS|                          BAMS|\n",
      "|                BAMS|                          BAMS|\n",
      "|                BHMS|                          BHMS|\n",
      "|                 BDS|                           BDS|\n",
      "|MBBS, MD - Genera...|                     MBBS, MD |\n",
      "|            BSc, BDS|                      BSc, BDS|\n",
      "+--------------------+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+------------------------------+\n",
      "|       Qualification|split(Qualification, -, -1)[0]|\n",
      "+--------------------+------------------------------+\n",
      "|BHMS, MD - Homeop...|                     BHMS, MD |\n",
      "|BAMS, MD - Ayurve...|                     BAMS, MD |\n",
      "|MBBS, MS - Otorhi...|                     MBBS, MS |\n",
      "| BSc - Zoology, BAMS|                          BSc |\n",
      "|                BAMS|                          BAMS|\n",
      "|                BAMS|                          BAMS|\n",
      "|                BHMS|                          BHMS|\n",
      "|                 BDS|                           BDS|\n",
      "|MBBS, MD - Genera...|                     MBBS, MD |\n",
      "|            BSc, BDS|                      BSc, BDS|\n",
      "+--------------------+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df[['Qualification']].show(10)\n",
    "df.select(col('Qualification'), split('Qualification','-')[0]).show(10)\n",
    "spark.sql(\"\"\" select Qualification, split(Qualification,'-')[0] from df_Table            \n",
    "            \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "709386c8-88b3-4b95-8222-41695f25611b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Fees|\n",
      "+----+\n",
      "| 800|\n",
      "| 700|\n",
      "| 200|\n",
      "| 250|\n",
      "| 300|\n",
      "| 100|\n",
      "| 650|\n",
      "| 350|\n",
      "| 150|\n",
      "| 500|\n",
      "| 600|\n",
      "| 750|\n",
      "| 400|\n",
      "|  50|\n",
      "+----+\n",
      "\n",
      "+--------------------+-----------+\n",
      "|       Qualification|Agg_Fee_Sum|\n",
      "+--------------------+-----------+\n",
      "|MBBS, MD - Dermat...|      400.0|\n",
      "|BDS, P.G Diploma ...|      200.0|\n",
      "|BDS, MDS - Oral &...|      400.0|\n",
      "|MDS-Oral Patholog...|      200.0|\n",
      "|BDS, MDS - Period...|      300.0|\n",
      "|BDS, MDS - Paedod...|      300.0|\n",
      "|                BAMS|     1750.0|\n",
      "|BAMS, Post Gradua...|       50.0|\n",
      "|MBBS, Diploma in ...|      300.0|\n",
      "|MD - Ayurveda Med...|      500.0|\n",
      "|Diploma in Dermat...|      500.0|\n",
      "|MBBS, MS - ENT, D...|      100.0|\n",
      "|MBBS, MS - ENT, D...|      500.0|\n",
      "|BDS, MDS - Period...|      500.0|\n",
      "| MBBS, MS, DNB - ENT|      700.0|\n",
      "|MD - General Medi...|      100.0|\n",
      "|MD - Dermatology ...|      250.0|\n",
      "|MBBS, MF- Homeopathy|      300.0|\n",
      "|MD - Dermatology,...|      600.0|\n",
      "|         MRCPS, MBBS|      100.0|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Fees').distinct().show()\n",
    "df.groupby('Qualification').agg(sum(col('Fees'))).select('Qualification',col('sum(Fees)').alias('Agg_Fee_Sum')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e0e71e8c-338c-4237-84f9-94a457c11fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|       Qualification|         Experience|\n",
      "+--------------------+-------------------+\n",
      "|BHMS, MD - Homeop...|24 years experience|\n",
      "|BAMS, MD - Ayurve...|12 years experience|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|\n",
      "| BSc - Zoology, BAMS|12 years experience|\n",
      "|                BAMS|20 years experience|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[['Qualification','Experience']].show(5)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01db08-4a79-4d7e-a44c-b1e0ef41418f",
   "metadata": {
    "tags": []
   },
   "source": [
    "for i in list(df.collect()):\n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0d4447b1-a6a0-46dd-8b04-658df8dcd881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+---------------+\n",
      "|               Place|         trim(Place)|        New|            New|\n",
      "+--------------------+--------------------+-----------+---------------+\n",
      "| Kakkanad, Ernakulam| Kakkanad, Ernakulam|  Ernakulam|Kakkanad       |\n",
      "|Whitefield, Banga...|Whitefield, Banga...|  Bangalore|Whitefield     |\n",
      "|Mathikere - BEL, ...|Mathikere - BEL, ...|  Bangalore|Mathikere - BEL|\n",
      "|Bannerghatta Road...|Bannerghatta Road...|  Bangalore|Bannerghatta Ro|\n",
      "|Keelkattalai, Che...|Keelkattalai, Che...|    Chennai|Keelkattalai   |\n",
      "|      Porur, Chennai|      Porur, Chennai|    Chennai|Porur          |\n",
      "|   Karol Bagh, Delhi|   Karol Bagh, Delhi|      Delhi|Karol Bagh     |\n",
      "|  Arekere, Bangalore|  Arekere, Bangalore|  Bangalore|Arekere        |\n",
      "| Old City, Hyderabad| Old City, Hyderabad|  Hyderabad|Old City       |\n",
      "|   Athani, Ernakulam|   Athani, Ernakulam|  Ernakulam|Athani         |\n",
      "|Thousand Lights, ...|Thousand Lights, ...|    Chennai|Thousand Lights|\n",
      "|Somajiguda, Hyder...|Somajiguda, Hyder...|  Hyderabad|Somajiguda     |\n",
      "|Coimbatore Raceco...|Coimbatore Raceco...| Coimbatore|Coimbatore Race|\n",
      "|Jubilee Hills, Hy...|Jubilee Hills, Hy...|  Hyderabad|Jubilee Hills  |\n",
      "|       Kondli, Delhi|       Kondli, Delhi|      Delhi|Kondli         |\n",
      "|Saroor Nagar, Hyd...|Saroor Nagar, Hyd...|  Hyderabad|Saroor Nagar   |\n",
      "|Tambaram West, Ch...|Tambaram West, Ch...|    Chennai|Tambaram West  |\n",
      "|Purasawakkam, Che...|Purasawakkam, Che...|    Chennai|Purasawakkam   |\n",
      "|     KPHB, Hyderabad|     KPHB, Hyderabad|  Hyderabad|KPHB           |\n",
      "|HSR Layout, Banga...|HSR Layout, Banga...|  Bangalore|HSR Layout     |\n",
      "+--------------------+--------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Place,trim(df.Place), split(col('Place'),',')[1].alias('New'),rpad(split(col('Place'),',')[0],15,\" \").alias('New')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e311f7b2-d4a3-4cad-ae9a-3d94212974cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+---------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|  Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+---------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|Homeopath|100% 16 Feedback ...| 100|\n",
      "|                BHMS|42 years experience|  null|   Karol Bagh, Delhi|Homeopath|                null| 200|\n",
      "|MBBS, MF- Homeopathy| 5 years experience|  null|Purasawakkam, Che...|Homeopath|                null| 300|\n",
      "|BHMS, Diploma in ...|12 years experience|   90%|Borivali West, Mu...|Homeopath|90% 2 Feedback Bo...| 300|\n",
      "|BHMS, M. D. Hom. ...|12 years experience|  100%|Dahisar West, Mumbai|Homeopath|100% 21 Feedback ...| 500|\n",
      "|MD - Homeopathy, ...|22 years experience|   99%|       Powai, Mumbai|Homeopath|Skin Disease Trea...| 500|\n",
      "|                BHMS| 5 years experience|  null|   Meera Bagh, Delhi|Homeopath|                null| 150|\n",
      "|                BHMS|22 years experience|  null|   Chattarpur, Delhi|Homeopath|                null| 200|\n",
      "|BHMS, MS - Psycho...|14 years experience|  100%|HSR Layout, Banga...|Homeopath|100% 43 Feedback ...| 200|\n",
      "|BHMS, Diploma In ...| 6 years experience|  null| Adambakkam, Chennai|Homeopath|                null| 150|\n",
      "|                BHMS|18 years experience|  null|   Mahalaxmi, Mumbai|Homeopath|                null| 100|\n",
      "|                BHMS|12 years experience|  100%|Kanakpura Road, B...|Homeopath|Pediaterics Skin ...| 500|\n",
      "|BHMS, MD - Homeop...| 9 years experience|  null|Yelahanka New Tow...|Homeopath|                null| 500|\n",
      "|                BHMS|12 years experience|  null| Nesapakkam, Chennai|Homeopath|                null| 100|\n",
      "|                BHMS|12 years experience|  null|Malleswaram, Bang...|Homeopath|Skin Allergy Trea...| 500|\n",
      "|                BHMS|26 years experience|   82%|BTM Layout 2nd St...|Homeopath|82% 15 Feedback B...| 200|\n",
      "|                BHMS| 8 years experience|  100%|South Extension 2...|Homeopath|100% 9 Feedback S...| 350|\n",
      "|BHMS, MD - Homeop...|36 years experience|  null|Kolenchery, Ernak...|Homeopath|                null| 250|\n",
      "+--------------------+-------------------+------+--------------------+---------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col('Profile') == 'Homeopath').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bc08e4d4-02d5-4cc0-9155-2a526ae154aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-------+\n",
      "|Qualification|         Experience|New_col|\n",
      "+-------------+-------------------+-------+\n",
      "|          BDS|10 years experience|   true|\n",
      "|          BDS|10 years experience|   true|\n",
      "|          BDS|10 years experience|   true|\n",
      "|          BDS|10 years experience|   true|\n",
      "+-------------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('New_col', df.Experience.isin ('10 years experience','24 years experience') & (df.Qualification == 'BDS')). \\\n",
    "        select('Qualification','Experience','New_col').where(col('New_col') == True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d835d4a1-2e67-4305-8597-44411980d078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97c22b6-e79e-4de6-ac4b-64e1ea5116d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|         Profile|Agg_Col|\n",
      "+----------------+-------+\n",
      "|  Dermatologists|10350.0|\n",
      "|        Ayurveda| 4100.0|\n",
      "|       Homeopath| 5100.0|\n",
      "|  ENT Specialist| 7050.0|\n",
      "|General Medicine| 8200.0|\n",
      "|         Dentist| 9650.0|\n",
      "+----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Profile').agg(sum('Fees')).select('Profile',col('sum(Fees)').alias('Agg_Col')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b556f298-ecc3-415e-a9f5-888fc2aee2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------+\n",
      "|         Profile|sum(Fees)|Count_Fees|\n",
      "+----------------+---------+----------+\n",
      "|  Dermatologists|  10350.0|        25|\n",
      "|        Ayurveda|   4100.0|        18|\n",
      "|       Homeopath|   5100.0|        18|\n",
      "|  ENT Specialist|   7050.0|        19|\n",
      "|General Medicine|   8200.0|        29|\n",
      "|         Dentist|   9650.0|        40|\n",
      "+----------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(col('Profile')).agg(sum(\"Fees\"),count(col(\"Fees\")).alias('Count_Fees')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b8278468-2277-484f-91ad-ae0e159c956f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5123f84c-1cc1-4438-a2b0-891a7531c1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(Fees)|\n",
      "+---------+\n",
      "|  44450.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby().agg(sum('Fees')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "49585e61-fad5-4cbf-9bdb-8d7c52c4ddba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+------------+\n",
      "|       Qualification|POWER(Fees, 2.0)|pow(Fees, 2)|\n",
      "+--------------------+----------------+------------+\n",
      "|BHMS, MD - Homeop...|         10000.0|     10000.0|\n",
      "|BAMS, MD - Ayurve...|        122500.0|    122500.0|\n",
      "|MBBS, MS - Otorhi...|         90000.0|     90000.0|\n",
      "| BSc - Zoology, BAMS|         62500.0|     62500.0|\n",
      "|                BAMS|         62500.0|     62500.0|\n",
      "|                BAMS|         10000.0|     10000.0|\n",
      "|                BHMS|         40000.0|     40000.0|\n",
      "|                 BDS|         40000.0|     40000.0|\n",
      "|MBBS, MD - Genera...|         10000.0|     10000.0|\n",
      "|            BSc, BDS|         10000.0|     10000.0|\n",
      "| MBBS, MS, DNB - ENT|        490000.0|    490000.0|\n",
      "|                BAMS|         10000.0|     10000.0|\n",
      "|            BDS, MDS|         40000.0|     40000.0|\n",
      "|BDS, MDS - Oral &...|        122500.0|    122500.0|\n",
      "|MBBS, Diploma in ...|        250000.0|    250000.0|\n",
      "|MBBS, MD - Genera...|         40000.0|     40000.0|\n",
      "|MBBS, Diploma in ...|         10000.0|     10000.0|\n",
      "|MBBS, MF- Homeopathy|         90000.0|     90000.0|\n",
      "|      MBBS, MS - ENT|        160000.0|    160000.0|\n",
      "|                MBBS|         22500.0|     22500.0|\n",
      "+--------------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Qualification', pow('Fees',2), expr(\"\"\"pow(Fees,2)\"\"\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d0591c29-9c6a-4b17-b753-ed0dcfbaf454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "15bf669b-a931-495b-9a35-a681615e1b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(Fees)|\n",
      "+---------+\n",
      "|  44450.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum('Fees')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d43ad849-bdb4-421d-84fc-19a236d170c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py\", line 458, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 602, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 692, in reducer_override\n",
      "    return self._function_reduce(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 565, in _function_reduce\n",
      "    return self._dynamic_function_reduce(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 546, in _dynamic_function_reduce\n",
      "    state = _function_getstate(func)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 157, in _function_getstate\n",
      "    f_globals_ref = _extract_code_globals(func.__code__)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 334, in _extract_code_globals\n",
      "    out_names = {names[oparg]: None for _, oparg in _walk_global_ops(co)}\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 334, in <dictcomp>\n",
      "    out_names = {names[oparg]: None for _, oparg in _walk_global_ops(co)}\n",
      "                 ~~~~~^^^^^^^\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: IndexError: tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py:458\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[0;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:602\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:692\u001b[0m, in \u001b[0;36mCloudPickler.reducer_override\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# fallback to save_global, including the Pickler's\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:565\u001b[0m, in \u001b[0;36mCloudPickler._function_reduce\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamic_function_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:546\u001b[0m, in \u001b[0;36mCloudPickler._dynamic_function_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    545\u001b[0m newargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_getnewargs(func)\n\u001b[1;32m--> 546\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43m_function_getstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (types\u001b[38;5;241m.\u001b[39mFunctionType, newargs, state, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    548\u001b[0m         _function_setstate)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:157\u001b[0m, in \u001b[0;36m_function_getstate\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m slotstate \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__qualname__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__closure__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__closure__\u001b[39m,\n\u001b[0;32m    155\u001b[0m }\n\u001b[1;32m--> 157\u001b[0m f_globals_ref \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_code_globals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__code__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m f_globals \u001b[38;5;241m=\u001b[39m {k: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f_globals_ref \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    159\u001b[0m              func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:334\u001b[0m, in \u001b[0;36m_extract_code_globals\u001b[1;34m(co)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# We use a dict with None values instead of a set to get a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# deterministic order (assuming Python 3.6+) and avoid introducing\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# non-deterministic pickle bytes as a results.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m out_names \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43moparg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moparg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_walk_global_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mco\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Declaring a function inside another one using the \"def ...\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# syntax generates a constant code object corresponding to the one\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# of the nested function's As the nested function may itself need\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# global variables, we need to introspect its code, extract its\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# globals, (look for code object in it's co_consts attribute..) and\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# add the result to code_globals\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:334\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# We use a dict with None values instead of a set to get a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# deterministic order (assuming Python 3.6+) and avoid introducing\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# non-deterministic pickle bytes as a results.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m out_names \u001b[38;5;241m=\u001b[39m {\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43moparg\u001b[49m\u001b[43m]\u001b[49m: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _, oparg \u001b[38;5;129;01min\u001b[39;00m _walk_global_ops(co)}\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Declaring a function inside another one using the \"def ...\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# syntax generates a constant code object corresponding to the one\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# of the nested function's As the nested function may itself need\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# global variables, we need to introspect its code, extract its\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# globals, (look for code object in it's co_consts attribute..) and\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# add the result to code_globals\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m schema \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[0;32m      2\u001b[0m                     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m,StringType(),\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m      3\u001b[0m                     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m,IntegerType(),\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m      4\u001b[0m                     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRole\u001b[39m\u001b[38;5;124m\"\u001b[39m,StringType(),\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHarshal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m22\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSWE\u001b[39m\u001b[38;5;124m\"\u001b[39m),(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMohit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m23\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDE\u001b[39m\u001b[38;5;124m\"\u001b[39m),(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuresh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSDET\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m----> 9\u001b[0m df_new \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\session.py:894\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    892\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[0;32m    893\u001b[0m     )\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    896\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\session.py:938\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    936\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 938\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_java_object_rdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mapplySchemaToPythonRDD(jrdd\u001b[38;5;241m.\u001b[39mrdd(), struct\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m    940\u001b[0m df \u001b[38;5;241m=\u001b[39m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\rdd.py:3113\u001b[0m, in \u001b[0;36mRDD._to_java_object_rdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3110\u001b[0m rdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pickled()\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mpythonToJava(\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\rdd.py:3505\u001b[0m, in \u001b[0;36mPipelinedRDD._jrdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3503\u001b[0m     profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3505\u001b[0m wrapped_func \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prev_jrdd_deserializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd_deserializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofiler\u001b[49m\n\u001b[0;32m   3507\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3510\u001b[0m python_rdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD(\n\u001b[0;32m   3511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_jrdd\u001b[38;5;241m.\u001b[39mrdd(), wrapped_func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreservesPartitioning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_barrier\n\u001b[0;32m   3512\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\rdd.py:3362\u001b[0m, in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m serializer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserializer should not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3361\u001b[0m command \u001b[38;5;241m=\u001b[39m (func, profiler, deserializer, serializer)\n\u001b[1;32m-> 3362\u001b[0m pickled_command, broadcast_vars, env, includes \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_for_python_RDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3363\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonFunction(\n\u001b[0;32m   3365\u001b[0m     \u001b[38;5;28mbytearray\u001b[39m(pickled_command),\n\u001b[0;32m   3366\u001b[0m     env,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3371\u001b[0m     sc\u001b[38;5;241m.\u001b[39m_javaAccumulator,\n\u001b[0;32m   3372\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\rdd.py:3345\u001b[0m, in \u001b[0;36m_prepare_for_python_RDD\u001b[1;34m(sc, command)\u001b[0m\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_python_RDD\u001b[39m(sc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkContext\u001b[39m\u001b[38;5;124m\"\u001b[39m, command: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, Any, Any, Any]:\n\u001b[0;32m   3343\u001b[0m     \u001b[38;5;66;03m# the serialized command will be compressed by broadcast\u001b[39;00m\n\u001b[0;32m   3344\u001b[0m     ser \u001b[38;5;241m=\u001b[39m CloudPickleSerializer()\n\u001b[1;32m-> 3345\u001b[0m     pickled_command \u001b[38;5;241m=\u001b[39m \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3346\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pickled_command) \u001b[38;5;241m>\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetBroadcastThreshold(sc\u001b[38;5;241m.\u001b[39m_jsc):  \u001b[38;5;66;03m# Default 1M\u001b[39;00m\n\u001b[0;32m   3348\u001b[0m         \u001b[38;5;66;03m# The broadcast will have same life cycle as created PythonRDD\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py:468\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    466\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not serialize object: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, emsg)\n\u001b[0;32m    467\u001b[0m print_exec(sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m--> 468\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPicklingError(msg)\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not serialize object: IndexError: tuple index out of range"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "                    StructField(\"Name\",StringType(),False),\n",
    "                    StructField(\"Age\",IntegerType(),False),\n",
    "                    StructField(\"Role\",StringType(),True)\n",
    "])\n",
    "\n",
    "data = [(\"Harshal\",22,\"SWE\"),(\"Mohit\",23,\"DE\"),(\"Suresh\",24,\"SDET\")]\n",
    "\n",
    "df_new = spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8179c265-4b96-4165-ac8d-4e88b0d81208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|ltrim(Qualification)|\n",
      "+--------------------+\n",
      "|BHMS, MD - Homeop...|\n",
      "|BAMS, MD - Ayurve...|\n",
      "|MBBS, MS - Otorhi...|\n",
      "| BSc - Zoology, BAMS|\n",
      "|                BAMS|\n",
      "|                BAMS|\n",
      "|                BHMS|\n",
      "|                 BDS|\n",
      "|MBBS, MD - Genera...|\n",
      "|            BSc, BDS|\n",
      "| MBBS, MS, DNB - ENT|\n",
      "|                BAMS|\n",
      "|            BDS, MDS|\n",
      "|BDS, MDS - Oral &...|\n",
      "|MBBS, Diploma in ...|\n",
      "|MBBS, MD - Genera...|\n",
      "|MBBS, Diploma in ...|\n",
      "|MBBS, MF- Homeopathy|\n",
      "|      MBBS, MS - ENT|\n",
      "|                MBBS|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(ltrim('Qualification')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "43ba1821-5974-4253-a1c8-b54444f97c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "990e50cd-0254-450f-a4e4-f2c8079b9743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|regexp_extract(Miscellaneous_Info, 100, 0)|\n",
      "+------------------------------------------+\n",
      "|                                       100|\n",
      "|                                          |\n",
      "|                                      null|\n",
      "|                                          |\n",
      "|                                       100|\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                          |\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                          |\n",
      "|                                          |\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                      null|\n",
      "|                                          |\n",
      "|                                       100|\n",
      "+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(regexp_extract('Miscellaneous_Info','100',0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fda8e452-a3d8-47b7-8834-e3f69aed542c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|round(CAST(Fees AS FLOAT), 5)|\n",
      "+-----------------------------+\n",
      "|                        100.0|\n",
      "|                        350.0|\n",
      "|                        300.0|\n",
      "|                        250.0|\n",
      "|                        250.0|\n",
      "+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(round(col('Fees').cast('float'),5)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5aaef8eb-7be5-469d-9a67-97962c4ed210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+------------------------------------------------------------------------------------------+\n",
      "|       Profile|Rating|CASE WHEN (Profile = Homeopath) THEN regexp_replace(Rating, 100%, Fake, 1) ELSE Rating END|\n",
      "+--------------+------+------------------------------------------------------------------------------------------+\n",
      "|     Homeopath|  100%|                                                                                      Fake|\n",
      "|      Ayurveda|   98%|                                                                                       98%|\n",
      "|ENT Specialist|  null|                                                                                      null|\n",
      "|      Ayurveda|  null|                                                                                      null|\n",
      "|      Ayurveda|  100%|                                                                                      100%|\n",
      "|      Ayurveda|  null|                                                                                      null|\n",
      "|     Homeopath|  null|                                                                                      null|\n",
      "+--------------+------+------------------------------------------------------------------------------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Profile','Rating',when(col('Profile')=='Homeopath',regexp_replace('Rating','100%','Fake')).otherwise(col('Rating'))).show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d560fada-d410-4a3a-a592-5cfa4fc7fd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------------+--------------------------------------------------------------------------+-------------------------------+-------------------------------------+\n",
      "|Today Date|date_add(Today Date, 130)|bround(months_between(date_add(Today Date, 131), current_date(), true), 0)|translate(current_date(), -, :)|to_date(current_timestamp(), yyyy-DD)|\n",
      "+----------+-------------------------+--------------------------------------------------------------------------+-------------------------------+-------------------------------------+\n",
      "|2023-10-05|               2024-02-12|                                                                       4.0|                     2023:10:05|                           2023-10-05|\n",
      "|2023-10-05|               2024-02-12|                                                                       4.0|                     2023:10:05|                           2023-10-05|\n",
      "|2023-10-05|               2024-02-12|                                                                       4.0|                     2023:10:05|                           2023-10-05|\n",
      "|2023-10-05|               2024-02-12|                                                                       4.0|                     2023:10:05|                           2023-10-05|\n",
      "|2023-10-05|               2024-02-12|                                                                       4.0|                     2023:10:05|                           2023-10-05|\n",
      "+----------+-------------------------+--------------------------------------------------------------------------+-------------------------------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('Today Date', current_date()).select('Today Date',date_add(col('Today Date'),130),\\\n",
    "                                                   bround(months_between(date_add(col('Today Date'),131),current_date()),0),\n",
    "                                                  translate(current_date(),'-',':'), to_date(current_timestamp(),'yyyy-DD')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "7be0fb09-0a36-453d-8c6c-d2730ba6119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "def square(x):\n",
    "    return (x**2)\n",
    "\n",
    "udf_function = udf(lambda x: square(x), IntegerType())\n",
    "\n",
    "spark.udf.register('square_sql',square)\n",
    "\n",
    "df.createOrReplaceTempView('testing')\n",
    "#df.select(udf_function(col('Fees')),col('Rating')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "25a6af04-e700-4119-910a-35b22be9a8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2716.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 353.0 failed 1 times, most recent failure: Lost task 0.0 in stage 353.0 (TID 410) (192.168.1.40 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:157)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 24 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\r\n\tat sun.reflect.GeneratedMethodAccessor122.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:157)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 24 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[481], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43m select *, square_sql(ifnull(Fees,0)) from testing\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:606\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o2716.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 353.0 failed 1 times, most recent failure: Lost task 0.0 in stage 353.0 (TID 410) (192.168.1.40 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:157)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 24 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\r\n\tat sun.reflect.GeneratedMethodAccessor122.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:189)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:157)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:176)\r\n\t... 24 more\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select *, square_sql(ifnull(Fees,0)) from testing\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "041d430c-e072-46eb-86a3-3ee052c662fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------------+\n",
      "|CAST(translate(Rating, %, ) AS INT)|(Rating IS NULL)|\n",
      "+-----------------------------------+----------------+\n",
      "|                                100|           false|\n",
      "|                                 98|           false|\n",
      "|                               null|            true|\n",
      "|                               null|            true|\n",
      "|                                100|           false|\n",
      "|                               null|            true|\n",
      "|                               null|            true|\n",
      "|                                 99|           false|\n",
      "+-----------------------------------+----------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(translate(col('Rating'),'%','').cast('integer'), isnull(col('Rating'))).show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "8315fac6-5269-4d37-9485-8cec21f569fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------+--------------------+----+----------+\n",
      "|       Qualification|         Experience|Rating|               Place| Profile|  Miscellaneous_Info|Fees|Rank_col_2|\n",
      "+--------------------+-------------------+------+--------------------+--------+--------------------+----+----------+\n",
      "| BAMS, MS - Ayurveda|10 years experience|  null|   Bakkarwala, Delhi|Ayurveda|                null| 150|         1|\n",
      "|                BAMS|12 years experience|   96%|  Dadar West, Mumbai|Ayurveda|96% 30 Feedback D...| 100|         1|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|Ayurveda|Bannerghatta Road...| 250|         2|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|Ayurveda|98% 76 Feedback W...| 350|         3|\n",
      "|BAMS, MD - Acupun...|15 years experience|  null|Anna Nagar East, ...|Ayurveda|                null| 250|         1|\n",
      "| BAMS, MS - Ayurveda|16 years experience|  100%|Yelahanka, Bangalore|Ayurveda|100% 3 Feedback Y...| 300|         1|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|Ayurveda|100% 4 Feedback K...| 250|         1|\n",
      "|                BAMS|20 years experience|  null|     Sagarpur, Delhi|Ayurveda|                null|  50|         2|\n",
      "|MD - Ayurveda Med...|20 years experience|  null|Goregaon West, Mu...|Ayurveda|                null| 500|         3|\n",
      "|                BAMS|27 years experience|  null|Dahisar East, Mumbai|Ayurveda|                null| 100|         1|\n",
      "|BAMS, Diploma in ...|31 years experience|  100%| RT Nagar, Bangalore|Ayurveda|100% 7 Feedback R...| 500|         1|\n",
      "|                BAMS| 7 years experience|  null|Somajiguda, Hyder...|Ayurveda|                null| 100|         1|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|Ayurveda|                null| 100|         1|\n",
      "|                BAMS| 8 years experience|  null|Saroor Nagar, Hyd...|Ayurveda|                null| 300|         2|\n",
      "|BAMS, Post Gradua...| 8 years experience|  null|Dahisar West, Mumbai|Ayurveda|                null|  50|         3|\n",
      "|                BAMS| 9 years experience|  null|    Chetpet, Chennai|Ayurveda|                null| 150|         1|\n",
      "|                BAMS| 9 years experience|  null| IP Extension, Delhi|Ayurveda|                null| 300|         2|\n",
      "|                BAMS| 9 years experience|  100%|     KPHB, Hyderabad|Ayurveda|Arthritis Managem...| 300|         2|\n",
      "|                 BDS|10 years experience|  100%|Vileparle East, M...| Dentist|Ceramic Veneers /...| 100|         1|\n",
      "|                 BDS|10 years experience|   99%|  Arekere, Bangalore| Dentist|Dental Fillings C...| 200|         2|\n",
      "+--------------------+-------------------+------+--------------------+--------+--------------------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "#df.withColumn('Window_Column',rank().over(Window.partitionBy('Profile').orderBy(col('Fees').desc()))).show()\n",
    "df.withColumn('Rank_col_2', dense_rank().over(Window.partitionBy('Profile','Experience').orderBy(col('Fees').asc_nulls_first()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8409f7c7-7e46-4552-b642-ef7433155e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1lal'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1' + 'lal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "58fa16b9-b918-4a56-af1c-0e6ef53ebe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "537be937-7d4d-46f2-bf59-8f09225fd29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pivoted = df.groupby('Profile').pivot('Fees').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "acce1ec9-481a-47db-b220-9e45b312dc60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|         Profile|\n",
      "+----------------+\n",
      "|  Dermatologists|\n",
      "|        Ayurveda|\n",
      "|       Homeopath|\n",
      "|  ENT Specialist|\n",
      "|General Medicine|\n",
      "|         Dentist|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0257cd2f-79a2-47c0-888d-43e29d16982d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'SparkContext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[443], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparkContext\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'SparkContext'"
     ]
    }
   ],
   "source": [
    "sc = spark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "cd26c040-6b29-42d3-8aa2-5d23f305e9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------+\n",
      "|Rating|coalesce(Rating, UNKNOWN)|\n",
      "+------+-------------------------+\n",
      "|  100%|                     100%|\n",
      "|   98%|                      98%|\n",
      "|  null|                  UNKNOWN|\n",
      "|  null|                  UNKNOWN|\n",
      "|  100%|                     100%|\n",
      "|  null|                  UNKNOWN|\n",
      "|  null|                  UNKNOWN|\n",
      "+------+-------------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Rating', coalesce('Rating',lit('UNKNOWN'))).show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f5f89017-b07a-4525-ae87-56b61fa3c52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+----------------------------+\n",
      "|current_date()|current_timestamp()    |to_timestamp(current_date())|\n",
      "+--------------+-----------------------+----------------------------+\n",
      "|2023-10-05    |2023-10-05 16:38:58.171|2023-10-05 00:00:00         |\n",
      "|2023-10-05    |2023-10-05 16:38:58.171|2023-10-05 00:00:00         |\n",
      "|2023-10-05    |2023-10-05 16:38:58.171|2023-10-05 00:00:00         |\n",
      "|2023-10-05    |2023-10-05 16:38:58.171|2023-10-05 00:00:00         |\n",
      "|2023-10-05    |2023-10-05 16:38:58.171|2023-10-05 00:00:00         |\n",
      "+--------------+-----------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date(), current_timestamp(),to_timestamp(current_date())).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "75f88c3f-0604-418b-a2c4-ff3ad8722c5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------------------------------------------------+\n",
      "|Rating|Rating|CASE WHEN (Rating IS NULL) THEN ABC ELSE Rating END|\n",
      "+------+------+---------------------------------------------------+\n",
      "|  100%|  100%|                                               100%|\n",
      "|   98%|   98%|                                                98%|\n",
      "|  null|  null|                                                ABC|\n",
      "|  null|  null|                                                ABC|\n",
      "|  100%|  100%|                                               100%|\n",
      "|  null|  null|                                                ABC|\n",
      "|  null|  null|                                                ABC|\n",
      "|   99%|   99%|                                                99%|\n",
      "|  null|  null|                                                ABC|\n",
      "|  null|  null|                                                ABC|\n",
      "|  null|  null|                                                ABC|\n",
      "|  null|  null|                                                ABC|\n",
      "|   98%|   98%|                                                98%|\n",
      "+------+------+---------------------------------------------------+\n",
      "only showing top 13 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Rating, df['Rating'],when(df['Rating'].isNull(),lit('ABC')).otherwise(df.Rating)).show(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "62ca2157-7b51-45bf-bd97-884524b5ed95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+---------------------------+\n",
      "|map(Profile, Rating)|             key|value|split(Qualification,  , -1)|\n",
      "+--------------------+----------------+-----+---------------------------+\n",
      "| {Homeopath -> 100%}|       Homeopath| 100%|       [BHMS,, MD, -, Ho...|\n",
      "|   {Ayurveda -> 98%}|        Ayurveda|  98%|       [BAMS,, MD, -, Ay...|\n",
      "|{ENT Specialist -...|  ENT Specialist| null|       [MBBS,, MS, -, Ot...|\n",
      "|  {Ayurveda -> null}|        Ayurveda| null|       [BSc, -, Zoology,...|\n",
      "|  {Ayurveda -> 100%}|        Ayurveda| 100%|                     [BAMS]|\n",
      "|  {Ayurveda -> null}|        Ayurveda| null|                     [BAMS]|\n",
      "| {Homeopath -> null}|       Homeopath| null|                     [BHMS]|\n",
      "|    {Dentist -> 99%}|         Dentist|  99%|                      [BDS]|\n",
      "|{General Medicine...|General Medicine| null|       [MBBS,, MD, -, Ge...|\n",
      "|   {Dentist -> null}|         Dentist| null|                [BSc,, BDS]|\n",
      "+--------------------+----------------+-----+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col('Profile'),col('Rating')),explode(create_map(col('Profile'),col('Rating'))), split(col('Qualification'),' ')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "04bc2578-9f4d-43c4-9c9b-c8f90c65e1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Test_Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "6af9f6fe-c525-4c13-ada3-d36db2c173bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|       Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|     Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|      Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|      Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|      Ayurveda|100% 4 Feedback K...| 250|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|      Ayurveda|                null| 100|\n",
      "+--------------------+-------------------+------+--------------------+--------------+--------------------+----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "42b340f7-513c-4ff6-9861-361b51b734d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Qualification','Experience','Rating','Place','Profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "ee640e78-b2fb-4b51-b8bb-22d8ee04f7be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|  Miscellaneous_Info|Fees|\n",
      "+--------------------+----+\n",
      "|100% 16 Feedback ...| 100|\n",
      "|98% 76 Feedback W...| 350|\n",
      "|                null| 300|\n",
      "|Bannerghatta Road...| 250|\n",
      "|100% 4 Feedback K...| 250|\n",
      "|                null| 100|\n",
      "|                null| 200|\n",
      "|Dental Fillings C...| 200|\n",
      "|                null| 100|\n",
      "|                null| 100|\n",
      "|                null| 700|\n",
      "|                null| 100|\n",
      "|98% 14 Feedback C...| 200|\n",
      "|Dental Crowns Fac...| 350|\n",
      "|                null| 500|\n",
      "|                null| 200|\n",
      "|                null| 100|\n",
      "|                null| 300|\n",
      "|79% 8 Feedback KP...| 400|\n",
      "|100% 4 Feedback H...| 150|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|         Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|       Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|        Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|  ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|        Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|        Ayurveda|100% 4 Feedback K...| 250|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|        Ayurveda|                null| 100|\n",
      "|                BHMS|42 years experience|  null|   Karol Bagh, Delhi|       Homeopath|                null| 200|\n",
      "|                 BDS|10 years experience|   99%|  Arekere, Bangalore|         Dentist|Dental Fillings C...| 200|\n",
      "|MBBS, MD - Genera...|14 years experience|  null| Old City, Hyderabad|General Medicine|                null| 100|\n",
      "|            BSc, BDS|23 years experience|  null|   Athani, Ernakulam|         Dentist|                null| 100|\n",
      "| MBBS, MS, DNB - ENT| 5 years experience|  null|Thousand Lights, ...|  ENT Specialist|                null| 700|\n",
      "|                BAMS| 7 years experience|  null|Somajiguda, Hyder...|        Ayurveda|                null| 100|\n",
      "|            BDS, MDS| 9 years experience|   98%|Coimbatore Raceco...|         Dentist|98% 14 Feedback C...| 200|\n",
      "|BDS, MDS - Oral &...|21 years experience|  null|Jubilee Hills, Hy...|         Dentist|Dental Crowns Fac...| 350|\n",
      "|MBBS, Diploma in ...|12 years experience|  null|       Kondli, Delhi|  ENT Specialist|                null| 500|\n",
      "|MBBS, MD - Genera...|10 years experience|  null|Saroor Nagar, Hyd...|General Medicine|                null| 200|\n",
      "|MBBS, Diploma in ...|24 years experience|  null|Tambaram West, Ch...|  ENT Specialist|                null| 100|\n",
      "|MBBS, MF- Homeopathy| 5 years experience|  null|Purasawakkam, Che...|       Homeopath|                null| 300|\n",
      "|      MBBS, MS - ENT|19 years experience|   79%|     KPHB, Hyderabad|  ENT Specialist|79% 8 Feedback KP...| 400|\n",
      "|                MBBS|19 years experience|  100%|HSR Layout, Banga...|General Medicine|100% 4 Feedback H...| 150|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(*cols).show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "7692b4ca-3be3-4816-8b50-6195db65bb68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------------+\n",
      "|Rating|test_ifnull|nvl(Rating, Not Present)|\n",
      "+------+-----------+------------------------+\n",
      "|  100%|       100%|                    100%|\n",
      "|   98%|        98%|                     98%|\n",
      "|  null|Not Present|             Not Present|\n",
      "|  null|Not Present|             Not Present|\n",
      "|  100%|       100%|                    100%|\n",
      "+------+-----------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select Rating,ifnull(Rating,'Not Present') as test_ifnull, nvl(Rating,'Not Present') from Test_Table\n",
    "\n",
    "\n",
    "        \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0c179b41-eef0-4849-978d-27e3fe26d9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+\n",
      "|       Qualification|         Experience|Rating|               Place|         Profile|  Miscellaneous_Info|Fees|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+\n",
      "|BHMS, MD - Homeop...|24 years experience|  100%| Kakkanad, Ernakulam|       Homeopath|100% 16 Feedback ...| 100|\n",
      "|BAMS, MD - Ayurve...|12 years experience|   98%|Whitefield, Banga...|        Ayurveda|98% 76 Feedback W...| 350|\n",
      "|MBBS, MS - Otorhi...| 9 years experience|  null|Mathikere - BEL, ...|  ENT Specialist|                null| 300|\n",
      "| BSc - Zoology, BAMS|12 years experience|  null|Bannerghatta Road...|        Ayurveda|Bannerghatta Road...| 250|\n",
      "|                BAMS|20 years experience|  100%|Keelkattalai, Che...|        Ayurveda|100% 4 Feedback K...| 250|\n",
      "|                BAMS| 8 years experience|  null|      Porur, Chennai|        Ayurveda|                null| 100|\n",
      "|                BHMS|42 years experience|  null|   Karol Bagh, Delhi|       Homeopath|                null| 200|\n",
      "|                 BDS|10 years experience|   99%|  Arekere, Bangalore|         Dentist|Dental Fillings C...| 200|\n",
      "|MBBS, MD - Genera...|14 years experience|  null| Old City, Hyderabad|General Medicine|                null| 100|\n",
      "|            BSc, BDS|23 years experience|  null|   Athani, Ernakulam|         Dentist|                null| 100|\n",
      "+--------------------+-------------------+------+--------------------+----------------+--------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "7755fe90-8afc-4f76-99f5-1a46ed057d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       Test|\n",
      "+-----------+\n",
      "|{100%, 100}|\n",
      "| {98%, 350}|\n",
      "|{null, 300}|\n",
      "|{null, 250}|\n",
      "+-----------+\n",
      "only showing top 4 rows\n",
      "\n",
      "+-----------------------+-----------+\n",
      "|struct(Rating, Profile)|       Test|\n",
      "+-----------------------+-----------+\n",
      "|      {100%, Homeopath}|{100%, 100}|\n",
      "|        {98%, Ayurveda}| {98%, 350}|\n",
      "|   {null, ENT Specia...|{null, 300}|\n",
      "|       {null, Ayurveda}|{null, 250}|\n",
      "+-----------------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr('(Rating, Fees) as Test')).show(4)\n",
    "df.select(struct('Rating','Profile'), struct('Rating','Fees').alias('Test')).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed64e6-daab-48a6-aa92-75f8fa225ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
